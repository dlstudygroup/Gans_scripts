{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gans_n_classes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvCMx6WZrec9"
      },
      "source": [
        "import os, math\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from tensorflow.keras.datasets import cifar10, mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input, BatchNormalization \n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Activation\n",
        "from tensorflow.keras.layers import Reshape, Conv2DTranspose, LeakyReLU\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.losses import mse, SparseCategoricalCrossentropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df9LBqdbriOh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "157b24ad-35cd-435a-95c3-da588ff78482"
      },
      "source": [
        "(x_train, y_train),(x_test, _) = mnist.load_data()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceVV7TVkmAYs"
      },
      "source": [
        "x_train = x_train.reshape(-1, 28, 28, 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LW9SJ9vprkAr",
        "outputId": "d889e93f-d7d9-4a05-b437-db6e6040b21d"
      },
      "source": [
        "image_size = x_train[0].shape[1]\n",
        "image_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyFFv7MotmPM"
      },
      "source": [
        "class ConvTransBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, kernel_size, strides):\n",
        "        super().__init__()\n",
        "        self.bn = BatchNormalization()  # check training flag\n",
        "        self.act = Activation(activation='relu')\n",
        "        self.conv2D_trans = Conv2DTranspose(filters=filters,\n",
        "                                kernel_size=kernel_size,\n",
        "                                strides=strides,\n",
        "                                padding='same')\n",
        "        \n",
        "    def call(self, inputs, training=False):\n",
        "        x = self.bn(inputs)\n",
        "        x = self.act(x)\n",
        "        return self.conv2D_trans(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INY9a1B4z7Wn"
      },
      "source": [
        "noise = np.random.uniform(0, 1, size=[10000, 100])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5VoZvOg0vtf"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Input(noise.shape[1]))\n",
        "model.add(Dense(14*14*32, activation=\"relu\"))\n",
        "model.add(Reshape([14, 14, 32]))\n",
        "model.add(ConvTransBlock(32, 5, 2))\n",
        "model.add(ConvTransBlock(16, 5, 1))\n",
        "model.add(Conv2DTranspose(1, 5, padding=\"same\", activation=\"sigmoid\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2Duk3Xc2l0w"
      },
      "source": [
        "model.compile(loss=\"MSE\", metrics=[\"MAE\"])\n",
        "model.fit(noise, x_train.reshape(-1, 28, 28, 1)[:10000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRIsDGBlxYOA"
      },
      "source": [
        "class Generator(tf.keras.models.Model):\n",
        "    def __init__(self, filters, kernel_size, resize_img):\n",
        "        super().__init__()\n",
        "        self.dense1 = Dense(resize_img * resize_img * filters[0])\n",
        "        self.reshape = Reshape([resize_img, resize_img, filters[0]])\n",
        "        self.conv2dtrans = []\n",
        "        for i, _filter in enumerate(filters):\n",
        "            if i <= 1:\n",
        "                strides = 2\n",
        "            else:\n",
        "                strides = 1\n",
        "            self.conv2dtrans.append(ConvTransBlock(_filter, kernel_size, strides))\n",
        "        \n",
        "        self.act = Activation(\"sigmoid\")\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = self.dense1(inputs)\n",
        "        x = self.reshape(x)\n",
        "        for conv in self.conv2dtrans:\n",
        "            x = conv(x)\n",
        "        return self.act(x)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6avJKo9G50jp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "27626f79-6040-4b5d-e3c8-8db817c75c41"
      },
      "source": [
        "gen = Generator(gen_layers_filter, gen_kernel_size, gen_resize_img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-a0d34591d352>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_layers_filter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_kernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_resize_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'gen_layers_filter' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIWu8eEf8dTx"
      },
      "source": [
        "gen.compile(loss=\"mse\", metrics=[\"mae\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YU1UT74M847B"
      },
      "source": [
        "gen.fit(noise, x_train.reshape(-1, 28, 28, 1)[:10000], batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUfyrKaXi7hx"
      },
      "source": [
        "def leaky_conv(filters, kernel_size, strides):\n",
        "    return Sequential([LeakyReLU(alpha=0.2),\n",
        "                       Conv2D(filters=filters,\n",
        "                       kernel_size=kernel_size,\n",
        "                       strides=strides,\n",
        "                       padding='same')])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZYAmEkxkrXU"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Input(x_train.shape[1:]))\n",
        "model.add(leaky_conv(32, 5, 2))\n",
        "model.add(leaky_conv(64, 5, 2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10))\n",
        "model.add(Activation(\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVF6HoMij1ot",
        "outputId": "d75060cb-5006-4225-c55e-cb868bd5bccc"
      },
      "source": [
        "model.compile(loss=SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_10 (Sequential)   (None, 14, 14, 32)        832       \n",
            "_________________________________________________________________\n",
            "sequential_11 (Sequential)   (None, 7, 7, 64)          51264     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                31370     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 83,466\n",
            "Trainable params: 83,466\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDFwZx5CmnvE"
      },
      "source": [
        "model.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuHfmqqgl1UE"
      },
      "source": [
        "class Discriminator(tf.keras.models.Model):\n",
        "    def __init__(self, filters, kernel_size):\n",
        "        super().__init__()\n",
        "        self.leaky_convs = []\n",
        "        for i, _filter in enumerate(filters):\n",
        "            if i < len(filters) - 1:\n",
        "                strides = 2\n",
        "            else:\n",
        "                strides = 1\n",
        "            self.leaky_convs.append(leaky_conv(_filter, kernel_size, strides))\n",
        "        self.flat = Flatten()\n",
        "        self.dense = Dense(1, activation='sigmoid')\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = inputs\n",
        "        for conv in self.leaky_convs:\n",
        "            x = conv(x)\n",
        "        x = self.flat(x)\n",
        "        return self.dense(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVKLSZL_ozgy"
      },
      "source": [
        "disc = Discriminator(disc_layers_filters, disc_kernel_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS9yU7CAo5sY"
      },
      "source": [
        "disc.compile(loss=\"categorical_crossentropy\", metrics=[\"mae\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZISAcJnpxrx"
      },
      "source": [
        "disc.fit(x_train, np.where(y_train < 5, 1, 0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWwkky2Hp413",
        "outputId": "4c4e0b19-e892-4505-b72d-2b077636df74"
      },
      "source": [
        "disc.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"discriminator_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_12 (Sequential)   (32, 14, 14, 32)          832       \n",
            "_________________________________________________________________\n",
            "sequential_13 (Sequential)   (32, 7, 7, 64)            51264     \n",
            "_________________________________________________________________\n",
            "sequential_14 (Sequential)   (32, 4, 4, 128)           204928    \n",
            "_________________________________________________________________\n",
            "sequential_15 (Sequential)   (32, 4, 4, 256)           819456    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  4097      \n",
            "=================================================================\n",
            "Total params: 1,080,577\n",
            "Trainable params: 1,080,577\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mprUKHR-qyH_"
      },
      "source": [
        "latent_size = 100\n",
        "batch_size = 64\n",
        "train_steps = 40000\n",
        "disc_lr = 2e-4\n",
        "disc_decay = 6e-8\n",
        "gen_lr = disc_lr/2\n",
        "gen_decay = disc_decay/2\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYGp4FOZ8_lI"
      },
      "source": [
        "disc_kernel_size = 5\n",
        "disc_layers_filters = [32, 64, 128, 256]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNBiGfK4s5v4"
      },
      "source": [
        "gen_resize_img = image_size // 4\n",
        "gen_kernel_size = 5\n",
        "gen_layers_filter = [128, 64, 32, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80EQpJupsYsu"
      },
      "source": [
        "gen = Generator(gen_layers_filter, gen_kernel_size, gen_resize_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ihpm4f_MQKfL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsGHWgavtkcd"
      },
      "source": [
        "disc = Discriminator(disc_layers_filters, disc_kernel_size)\n",
        "disc.compile(loss='binary_crossentropy',\n",
        "             optimizer=RMSprop(learning_rate=disc_lr, decay=disc_decay),\n",
        "             metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dQJ7JIUuAF1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d083941-2b98-463d-c397-aa5cd9083415"
      },
      "source": [
        "def build_gan():\n",
        "    # disc.trainable = False\n",
        "    gan = Sequential(name='gan_model')\n",
        "    gan.add(Input([100,]))\n",
        "    gan.add(gen)\n",
        "    gan.add(disc)\n",
        "    gan.summary()\n",
        "    gan.compile(loss='binary_crossentropy',\n",
        "                optimizer=RMSprop(learning_rate=gen_lr, decay=gen_decay),\n",
        "                metrics=['accuracy'])            \n",
        "    return gan   \n",
        "\n",
        "\n",
        "gan = build_gan()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"gan_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "generator_1 (Generator)      (None, 28, 28, 1)         1301505   \n",
            "_________________________________________________________________\n",
            "discriminator_2 (Discriminat (None, 1)                 1080577   \n",
            "=================================================================\n",
            "Total params: 2,382,082\n",
            "Trainable params: 2,381,378\n",
            "Non-trainable params: 704\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diElXoXzFgLe",
        "outputId": "02b79d82-806f-4201-94f4-5e3e034e9e06"
      },
      "source": [
        "for layer in gan.layers:\n",
        "    print(layer.trainable)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9zEUeIpNjsK"
      },
      "source": [
        "def plot_images(generator,\n",
        "                noise_input,\n",
        "                noise_label=None,\n",
        "                noise_codes=None,\n",
        "                show=False,\n",
        "                step=0,\n",
        "                model_name=\"gan\"):\n",
        "    \"\"\"Generate fake images and plot them\n",
        "\n",
        "    For visualization purposes, generate fake images\n",
        "    then plot them in a square grid\n",
        "\n",
        "    # Arguments\n",
        "        generator (Model): The Generator Model for \n",
        "            fake images generation\n",
        "        noise_input (ndarray): Array of z-vectors\n",
        "        show (bool): Whether to show plot or not\n",
        "        step (int): Appended to filename of the save images\n",
        "        model_name (string): Model name\n",
        "\n",
        "    \"\"\"\n",
        "    # os.makedirs(model_name, exist_ok=True)\n",
        "    # filename = os.path.join(model_name, \"%05d.png\" % step)\n",
        "    rows = int(math.sqrt(noise_input.shape[0]))\n",
        "    if noise_label is not None:\n",
        "        noise_input = [noise_input, noise_label]\n",
        "        if noise_codes is not None:\n",
        "            noise_input += noise_codes\n",
        "\n",
        "    images = generator.predict(noise_input)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    num_images = images.shape[0]\n",
        "    image_size = images.shape[1]\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(rows, rows, i + 1)\n",
        "        image = np.reshape(images[i], [image_size, image_size])\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.axis('off')\n",
        "    # plt.savefig(filename)\n",
        "    if show:\n",
        "        \n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close('all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbex8Ww8H03-"
      },
      "source": [
        "# Train the Discriminator and Adversarial Networks\n",
        "def train(models, x_train):\n",
        "    generator, discriminator, gan = models \n",
        "    # batch_size, latent_size, train_step, model_name = params\n",
        "    save_interval = 500\n",
        "    noise_input = np.random.uniform(-1.0, 1.0, size=[16, latent_size]) \n",
        "    train_size = x_train.shape[0]\n",
        "\n",
        "    for i in range(train_steps):\n",
        "        rand_indexes = np.random.randint(0, train_size, size=batch_size)\n",
        "        real_images = x_train[rand_indexes]\n",
        "        noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n",
        "        fake_images = generator.predict(noise)        \n",
        "        x = np.concatenate((real_images, fake_images)) # same size\n",
        "        y = np.ones([2 * batch_size, 1])\n",
        "        y[batch_size:, :] = 0.0\n",
        "        discriminator.trainable = True\n",
        "        loss, acc = discriminator.train_on_batch(x, y)\n",
        "        # log = \"%d: [discriminator loss: %f, acc: %f]\" % (i, loss, acc)\n",
        "        log = f'{i}: [discriminator loss: {loss}, acc: {acc}]'\n",
        "        discriminator.trainable = False\n",
        "\n",
        "        noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n",
        "        y = np.ones([batch_size, 1])        \n",
        "        loss, acc = gan.train_on_batch(noise, y)\n",
        "        log = \"%s [gan loss: %f, acc: %f]\" % (log, loss, acc)\n",
        "        print(log)\n",
        "        if (i + 1) % save_interval == 0:\n",
        "            # plot generator images on a periodic basis\n",
        "            plot_images(generator,\n",
        "                        noise_input=noise_input,\n",
        "                        show=True,\n",
        "                        step=(i + 1),\n",
        "                        model_name='gan_model')\n",
        "    \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3_7RVfcXIbaR",
        "outputId": "7c83452b-d772-4595-acbf-53c13d9bf149"
      },
      "source": [
        "train(models=[gen, disc, gan], x_train=x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: [discriminator loss: 3.310608148574829, acc: 0.5390625] [gan loss: 0.442984, acc: 1.000000]\n",
            "1: [discriminator loss: 0.759007453918457, acc: 0.5] [gan loss: 0.181721, acc: 1.000000]\n",
            "2: [discriminator loss: 0.9960637092590332, acc: 0.5] [gan loss: 0.076730, acc: 1.000000]\n",
            "3: [discriminator loss: 1.0921070575714111, acc: 0.5] [gan loss: 0.047926, acc: 1.000000]\n",
            "4: [discriminator loss: 1.1062705516815186, acc: 0.5] [gan loss: 0.037410, acc: 1.000000]\n",
            "5: [discriminator loss: 1.0864193439483643, acc: 0.5] [gan loss: 0.031826, acc: 1.000000]\n",
            "6: [discriminator loss: 1.050199031829834, acc: 0.5] [gan loss: 0.027467, acc: 1.000000]\n",
            "7: [discriminator loss: 1.0036964416503906, acc: 0.5] [gan loss: 0.024138, acc: 1.000000]\n",
            "8: [discriminator loss: 0.9490150213241577, acc: 0.5] [gan loss: 0.021317, acc: 1.000000]\n",
            "9: [discriminator loss: 0.8897984027862549, acc: 0.5] [gan loss: 0.019116, acc: 1.000000]\n",
            "10: [discriminator loss: 0.8305274248123169, acc: 0.5] [gan loss: 0.017024, acc: 1.000000]\n",
            "11: [discriminator loss: 0.7729439735412598, acc: 0.5] [gan loss: 0.014935, acc: 1.000000]\n",
            "12: [discriminator loss: 0.7202285528182983, acc: 0.5] [gan loss: 0.013088, acc: 1.000000]\n",
            "13: [discriminator loss: 0.6698479056358337, acc: 0.5] [gan loss: 0.011458, acc: 1.000000]\n",
            "14: [discriminator loss: 0.6231204271316528, acc: 0.5] [gan loss: 0.010124, acc: 1.000000]\n",
            "15: [discriminator loss: 0.5762726664543152, acc: 0.5] [gan loss: 0.008959, acc: 1.000000]\n",
            "16: [discriminator loss: 0.5311927795410156, acc: 0.5] [gan loss: 0.007830, acc: 1.000000]\n",
            "17: [discriminator loss: 0.49101725220680237, acc: 0.5] [gan loss: 0.006703, acc: 1.000000]\n",
            "18: [discriminator loss: 0.4567323923110962, acc: 0.5] [gan loss: 0.005788, acc: 1.000000]\n",
            "19: [discriminator loss: 0.42558735609054565, acc: 0.5] [gan loss: 0.005055, acc: 1.000000]\n",
            "20: [discriminator loss: 0.3976978659629822, acc: 0.5] [gan loss: 0.004388, acc: 1.000000]\n",
            "21: [discriminator loss: 0.37392497062683105, acc: 0.5] [gan loss: 0.003761, acc: 1.000000]\n",
            "22: [discriminator loss: 0.35295581817626953, acc: 0.5] [gan loss: 0.003300, acc: 1.000000]\n",
            "23: [discriminator loss: 0.33323943614959717, acc: 1.0] [gan loss: 0.002919, acc: 1.000000]\n",
            "24: [discriminator loss: 0.3146384358406067, acc: 1.0] [gan loss: 0.002572, acc: 1.000000]\n",
            "25: [discriminator loss: 0.2971363365650177, acc: 1.0] [gan loss: 0.002301, acc: 1.000000]\n",
            "26: [discriminator loss: 0.2798105478286743, acc: 1.0] [gan loss: 0.002092, acc: 1.000000]\n",
            "27: [discriminator loss: 0.2618067264556885, acc: 1.0] [gan loss: 0.001916, acc: 1.000000]\n",
            "28: [discriminator loss: 0.24390673637390137, acc: 1.0] [gan loss: 0.001771, acc: 1.000000]\n",
            "29: [discriminator loss: 0.22500918805599213, acc: 1.0] [gan loss: 0.001659, acc: 1.000000]\n",
            "30: [discriminator loss: 0.20512525737285614, acc: 1.0] [gan loss: 0.001574, acc: 1.000000]\n",
            "31: [discriminator loss: 0.18553553521633148, acc: 1.0] [gan loss: 0.001455, acc: 1.000000]\n",
            "32: [discriminator loss: 0.16584646701812744, acc: 1.0] [gan loss: 0.001322, acc: 1.000000]\n",
            "33: [discriminator loss: 0.1468852460384369, acc: 1.0] [gan loss: 0.001202, acc: 1.000000]\n",
            "34: [discriminator loss: 0.15069513022899628, acc: 0.9921875] [gan loss: 0.000008, acc: 1.000000]\n",
            "35: [discriminator loss: 0.3374537229537964, acc: 0.9765625] [gan loss: 0.000027, acc: 1.000000]\n",
            "36: [discriminator loss: 0.25098997354507446, acc: 1.0] [gan loss: 0.000045, acc: 1.000000]\n",
            "37: [discriminator loss: 0.21827757358551025, acc: 1.0] [gan loss: 0.000065, acc: 1.000000]\n",
            "38: [discriminator loss: 0.1960754245519638, acc: 1.0] [gan loss: 0.000085, acc: 1.000000]\n",
            "39: [discriminator loss: 0.1777626872062683, acc: 1.0] [gan loss: 0.000108, acc: 1.000000]\n",
            "40: [discriminator loss: 0.16198879480361938, acc: 1.0] [gan loss: 0.000128, acc: 1.000000]\n",
            "41: [discriminator loss: 0.14816820621490479, acc: 1.0] [gan loss: 0.000144, acc: 1.000000]\n",
            "42: [discriminator loss: 0.1358855664730072, acc: 1.0] [gan loss: 0.000157, acc: 1.000000]\n",
            "43: [discriminator loss: 0.12429267168045044, acc: 1.0] [gan loss: 0.000166, acc: 1.000000]\n",
            "44: [discriminator loss: 0.11377303302288055, acc: 1.0] [gan loss: 0.000170, acc: 1.000000]\n",
            "45: [discriminator loss: 0.10348644852638245, acc: 1.0] [gan loss: 0.000173, acc: 1.000000]\n",
            "46: [discriminator loss: 0.09370759129524231, acc: 1.0] [gan loss: 0.000172, acc: 1.000000]\n",
            "47: [discriminator loss: 0.08463367074728012, acc: 1.0] [gan loss: 0.000170, acc: 1.000000]\n",
            "48: [discriminator loss: 0.07594124972820282, acc: 1.0] [gan loss: 0.000164, acc: 1.000000]\n",
            "49: [discriminator loss: 0.06800166517496109, acc: 1.0] [gan loss: 0.000157, acc: 1.000000]\n",
            "50: [discriminator loss: 0.060752984136343, acc: 1.0] [gan loss: 0.000150, acc: 1.000000]\n",
            "51: [discriminator loss: 0.05409516394138336, acc: 1.0] [gan loss: 0.000127, acc: 1.000000]\n",
            "52: [discriminator loss: 0.04892725124955177, acc: 1.0] [gan loss: 0.000123, acc: 1.000000]\n",
            "53: [discriminator loss: 0.2567470371723175, acc: 0.9765625] [gan loss: 0.000000, acc: 1.000000]\n",
            "54: [discriminator loss: 0.38074082136154175, acc: 0.5078125] [gan loss: 0.000000, acc: 1.000000]\n",
            "55: [discriminator loss: 0.22716018557548523, acc: 1.0] [gan loss: 0.000001, acc: 1.000000]\n",
            "56: [discriminator loss: 0.17973247170448303, acc: 1.0] [gan loss: 0.000001, acc: 1.000000]\n",
            "57: [discriminator loss: 0.15363705158233643, acc: 1.0] [gan loss: 0.000001, acc: 1.000000]\n",
            "58: [discriminator loss: 0.1349499374628067, acc: 1.0] [gan loss: 0.000001, acc: 1.000000]\n",
            "59: [discriminator loss: 0.12237250804901123, acc: 1.0] [gan loss: 0.000002, acc: 1.000000]\n",
            "60: [discriminator loss: 0.11084109544754028, acc: 1.0] [gan loss: 0.000002, acc: 1.000000]\n",
            "61: [discriminator loss: 0.10139396041631699, acc: 1.0] [gan loss: 0.000003, acc: 1.000000]\n",
            "62: [discriminator loss: 0.09353489428758621, acc: 1.0] [gan loss: 0.000003, acc: 1.000000]\n",
            "63: [discriminator loss: 0.0862402617931366, acc: 1.0] [gan loss: 0.000003, acc: 1.000000]\n",
            "64: [discriminator loss: 0.07963494956493378, acc: 1.0] [gan loss: 0.000004, acc: 1.000000]\n",
            "65: [discriminator loss: 0.07411995530128479, acc: 1.0] [gan loss: 0.000004, acc: 1.000000]\n",
            "66: [discriminator loss: 0.06812373548746109, acc: 1.0] [gan loss: 0.000005, acc: 1.000000]\n",
            "67: [discriminator loss: 0.0632273331284523, acc: 1.0] [gan loss: 0.000005, acc: 1.000000]\n",
            "68: [discriminator loss: 0.05850263312458992, acc: 1.0] [gan loss: 0.000005, acc: 1.000000]\n",
            "69: [discriminator loss: 0.05378992110490799, acc: 1.0] [gan loss: 0.000006, acc: 1.000000]\n",
            "70: [discriminator loss: 0.04968131333589554, acc: 1.0] [gan loss: 0.000006, acc: 1.000000]\n",
            "71: [discriminator loss: 0.04561477154493332, acc: 1.0] [gan loss: 0.000006, acc: 1.000000]\n",
            "72: [discriminator loss: 0.04201792925596237, acc: 1.0] [gan loss: 0.000007, acc: 1.000000]\n",
            "73: [discriminator loss: 0.038289062678813934, acc: 1.0] [gan loss: 0.000007, acc: 1.000000]\n",
            "74: [discriminator loss: 0.035234484821558, acc: 1.0] [gan loss: 0.000007, acc: 1.000000]\n",
            "75: [discriminator loss: 0.03205267712473869, acc: 1.0] [gan loss: 0.000008, acc: 1.000000]\n",
            "76: [discriminator loss: 0.029211875051259995, acc: 1.0] [gan loss: 0.000008, acc: 1.000000]\n",
            "77: [discriminator loss: 0.026597920805215836, acc: 1.0] [gan loss: 0.000008, acc: 1.000000]\n",
            "78: [discriminator loss: 0.024083949625492096, acc: 1.0] [gan loss: 0.000008, acc: 1.000000]\n",
            "79: [discriminator loss: 0.021788671612739563, acc: 1.0] [gan loss: 0.000008, acc: 1.000000]\n",
            "80: [discriminator loss: 0.019783664494752884, acc: 1.0] [gan loss: 0.000008, acc: 1.000000]\n",
            "81: [discriminator loss: 0.017981987446546555, acc: 1.0] [gan loss: 0.000008, acc: 1.000000]\n",
            "82: [discriminator loss: 0.0163649320602417, acc: 1.0] [gan loss: 0.000008, acc: 1.000000]\n",
            "83: [discriminator loss: 0.014771394431591034, acc: 1.0] [gan loss: 0.000008, acc: 1.000000]\n",
            "84: [discriminator loss: 0.013448802754282951, acc: 1.0] [gan loss: 0.000008, acc: 1.000000]\n",
            "85: [discriminator loss: 0.0122467540204525, acc: 1.0] [gan loss: 0.000007, acc: 1.000000]\n",
            "86: [discriminator loss: 0.011144911870360374, acc: 1.0] [gan loss: 0.000007, acc: 1.000000]\n",
            "87: [discriminator loss: 0.010103925131261349, acc: 1.0] [gan loss: 0.000007, acc: 1.000000]\n",
            "88: [discriminator loss: 0.00925428606569767, acc: 1.0] [gan loss: 0.000006, acc: 1.000000]\n",
            "89: [discriminator loss: 0.008433908224105835, acc: 1.0] [gan loss: 0.000006, acc: 1.000000]\n",
            "90: [discriminator loss: 0.007728276774287224, acc: 1.0] [gan loss: 0.000006, acc: 1.000000]\n",
            "91: [discriminator loss: 0.007027308456599712, acc: 1.0] [gan loss: 0.000005, acc: 1.000000]\n",
            "92: [discriminator loss: 0.0064370278269052505, acc: 1.0] [gan loss: 0.000005, acc: 1.000000]\n",
            "93: [discriminator loss: 0.005904245190322399, acc: 1.0] [gan loss: 0.000005, acc: 1.000000]\n",
            "94: [discriminator loss: 0.005414855666458607, acc: 1.0] [gan loss: 0.000005, acc: 1.000000]\n",
            "95: [discriminator loss: 0.0049863047897815704, acc: 1.0] [gan loss: 0.000004, acc: 1.000000]\n",
            "96: [discriminator loss: 0.004576499108225107, acc: 1.0] [gan loss: 0.000004, acc: 1.000000]\n",
            "97: [discriminator loss: 0.004194972105324268, acc: 1.0] [gan loss: 0.000004, acc: 1.000000]\n",
            "98: [discriminator loss: 0.0038260645233094692, acc: 1.0] [gan loss: 0.000004, acc: 1.000000]\n",
            "99: [discriminator loss: 0.0035880696959793568, acc: 1.0] [gan loss: 0.000003, acc: 1.000000]\n",
            "100: [discriminator loss: 0.0032721010502427816, acc: 1.0] [gan loss: 0.000003, acc: 1.000000]\n",
            "101: [discriminator loss: 0.0030568845104426146, acc: 1.0] [gan loss: 0.000003, acc: 1.000000]\n",
            "102: [discriminator loss: 0.0028077345341444016, acc: 1.0] [gan loss: 0.000003, acc: 1.000000]\n",
            "103: [discriminator loss: 0.0025668013840913773, acc: 1.0] [gan loss: 0.000003, acc: 1.000000]\n",
            "104: [discriminator loss: 0.002396055031567812, acc: 1.0] [gan loss: 0.000003, acc: 1.000000]\n",
            "105: [discriminator loss: 0.0022263748105615377, acc: 1.0] [gan loss: 0.000002, acc: 1.000000]\n",
            "106: [discriminator loss: 0.002026581671088934, acc: 1.0] [gan loss: 0.000002, acc: 1.000000]\n",
            "107: [discriminator loss: 0.6161744594573975, acc: 0.9921875] [gan loss: 0.000000, acc: 1.000000]\n",
            "108: [discriminator loss: 0.7399725914001465, acc: 0.5] [gan loss: 0.000000, acc: 1.000000]\n",
            "109: [discriminator loss: 0.032861217856407166, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "110: [discriminator loss: 0.028736894950270653, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "111: [discriminator loss: 0.02660568803548813, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "112: [discriminator loss: 0.023840371519327164, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "113: [discriminator loss: 0.021975304931402206, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "114: [discriminator loss: 0.019847683608531952, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "115: [discriminator loss: 0.01873919554054737, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "116: [discriminator loss: 0.017136458307504654, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "117: [discriminator loss: 0.01640724018216133, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "118: [discriminator loss: 0.015053501352667809, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "119: [discriminator loss: 0.014657081104815006, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "120: [discriminator loss: 0.013493457809090614, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "121: [discriminator loss: 0.012416399084031582, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "122: [discriminator loss: 0.012234683148562908, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "123: [discriminator loss: 0.011231042444705963, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "124: [discriminator loss: 0.010777486488223076, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "125: [discriminator loss: 0.010382252745330334, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "126: [discriminator loss: 0.009872052818536758, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "127: [discriminator loss: 0.009707247838377953, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "128: [discriminator loss: 0.009219381958246231, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "129: [discriminator loss: 0.008560942485928535, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "130: [discriminator loss: 0.008248651400208473, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "131: [discriminator loss: 0.007741663604974747, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "132: [discriminator loss: 0.007539493963122368, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "133: [discriminator loss: 0.007356949150562286, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "134: [discriminator loss: 0.007037355098873377, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "135: [discriminator loss: 0.006470673251897097, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "136: [discriminator loss: 0.006419850513339043, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "137: [discriminator loss: 0.006102052051573992, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "138: [discriminator loss: 0.00573321059346199, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "139: [discriminator loss: 0.005542129278182983, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "140: [discriminator loss: 0.005243243649601936, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "141: [discriminator loss: 0.004943052306771278, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "142: [discriminator loss: 0.004689355380833149, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "143: [discriminator loss: 0.004565086215734482, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "144: [discriminator loss: 0.004430531524121761, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "145: [discriminator loss: 0.004123847931623459, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "146: [discriminator loss: 0.0039977324195206165, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "147: [discriminator loss: 0.003909057006239891, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "148: [discriminator loss: 0.0035385601222515106, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "149: [discriminator loss: 0.0033497645054012537, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "150: [discriminator loss: 0.003277695272117853, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "151: [discriminator loss: 0.003044992219656706, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "152: [discriminator loss: 0.0029607200995087624, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "153: [discriminator loss: 0.0027749452274292707, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "154: [discriminator loss: 0.0026583329308778048, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "155: [discriminator loss: 0.0025480003096163273, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "156: [discriminator loss: 0.0023745023645460606, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "157: [discriminator loss: 0.0023451135493814945, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "158: [discriminator loss: 0.002229773672297597, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "159: [discriminator loss: 0.002245711162686348, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "160: [discriminator loss: 0.00202069990336895, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "161: [discriminator loss: 0.002101379679515958, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "162: [discriminator loss: 0.0019031512783840299, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "163: [discriminator loss: 0.0017167376354336739, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "164: [discriminator loss: 0.0017331152921542525, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "165: [discriminator loss: 0.0016584738623350859, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "166: [discriminator loss: 0.0015893627423793077, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "167: [discriminator loss: 0.0015197738539427519, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "168: [discriminator loss: 0.0014493799535557628, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "169: [discriminator loss: 0.0015067332424223423, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "170: [discriminator loss: 0.0014147948240861297, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "171: [discriminator loss: 0.0013022092171013355, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "172: [discriminator loss: 0.001356590655632317, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "173: [discriminator loss: 0.0013591801980510354, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "174: [discriminator loss: 0.0011683162301778793, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "175: [discriminator loss: 0.0011852392926812172, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "176: [discriminator loss: 0.0013131053419783711, acc: 1.0] [gan loss: 0.000000, acc: 1.000000]\n",
            "177: [discriminator loss: 0.0015575871802866459, acc: 1.0] [gan loss: 0.000001, acc: 1.000000]\n",
            "178: [discriminator loss: 0.00211278535425663, acc: 1.0] [gan loss: 0.000001, acc: 1.000000]\n",
            "179: [discriminator loss: 0.00649572629481554, acc: 1.0] [gan loss: 0.001238, acc: 1.000000]\n",
            "180: [discriminator loss: 0.12051553279161453, acc: 0.9921875] [gan loss: 5.829783, acc: 0.000000]\n",
            "181: [discriminator loss: 7.089734572218731e-05, acc: 1.0] [gan loss: 0.000159, acc: 1.000000]\n",
            "182: [discriminator loss: 8.137579425238073e-05, acc: 1.0] [gan loss: 0.000158, acc: 1.000000]\n",
            "183: [discriminator loss: 9.514116391073912e-05, acc: 1.0] [gan loss: 0.000159, acc: 1.000000]\n",
            "184: [discriminator loss: 9.795415826374665e-05, acc: 1.0] [gan loss: 0.000160, acc: 1.000000]\n",
            "185: [discriminator loss: 0.00010744754399638623, acc: 1.0] [gan loss: 0.000162, acc: 1.000000]\n",
            "186: [discriminator loss: 0.00011985908349743113, acc: 1.0] [gan loss: 0.000163, acc: 1.000000]\n",
            "187: [discriminator loss: 0.00012677739141508937, acc: 1.0] [gan loss: 0.000166, acc: 1.000000]\n",
            "188: [discriminator loss: 0.00013817602302879095, acc: 1.0] [gan loss: 0.000172, acc: 1.000000]\n",
            "189: [discriminator loss: 0.00016617031360510737, acc: 1.0] [gan loss: 0.000174, acc: 1.000000]\n",
            "190: [discriminator loss: 0.00015963343321345747, acc: 1.0] [gan loss: 0.000178, acc: 1.000000]\n",
            "191: [discriminator loss: 0.00018472332158125937, acc: 1.0] [gan loss: 0.000185, acc: 1.000000]\n",
            "192: [discriminator loss: 0.00018838324467651546, acc: 1.0] [gan loss: 0.000192, acc: 1.000000]\n",
            "193: [discriminator loss: 0.00021004414884373546, acc: 1.0] [gan loss: 0.000201, acc: 1.000000]\n",
            "194: [discriminator loss: 0.00022169030853547156, acc: 1.0] [gan loss: 0.000202, acc: 1.000000]\n",
            "195: [discriminator loss: 0.00022611077292822301, acc: 1.0] [gan loss: 0.000210, acc: 1.000000]\n",
            "196: [discriminator loss: 0.0002703320642467588, acc: 1.0] [gan loss: 0.000230, acc: 1.000000]\n",
            "197: [discriminator loss: 0.00024299314827658236, acc: 1.0] [gan loss: 0.000246, acc: 1.000000]\n",
            "198: [discriminator loss: 0.0002795731124933809, acc: 1.0] [gan loss: 0.000271, acc: 1.000000]\n",
            "199: [discriminator loss: 0.00028304033912718296, acc: 1.0] [gan loss: 0.000302, acc: 1.000000]\n",
            "200: [discriminator loss: 0.0002771210274659097, acc: 1.0] [gan loss: 0.000335, acc: 1.000000]\n",
            "201: [discriminator loss: 0.000271131080808118, acc: 1.0] [gan loss: 0.000368, acc: 1.000000]\n",
            "202: [discriminator loss: 0.0002956256503239274, acc: 1.0] [gan loss: 0.000417, acc: 1.000000]\n",
            "203: [discriminator loss: 0.00028844011831097305, acc: 1.0] [gan loss: 0.000473, acc: 1.000000]\n",
            "204: [discriminator loss: 0.00027888515614904463, acc: 1.0] [gan loss: 0.000542, acc: 1.000000]\n",
            "205: [discriminator loss: 0.0002590957737993449, acc: 1.0] [gan loss: 0.000611, acc: 1.000000]\n",
            "206: [discriminator loss: 0.00027264904929324985, acc: 1.0] [gan loss: 0.000678, acc: 1.000000]\n",
            "207: [discriminator loss: 0.0002709220862016082, acc: 1.0] [gan loss: 0.000770, acc: 1.000000]\n",
            "208: [discriminator loss: 0.00029848242411389947, acc: 1.0] [gan loss: 0.000901, acc: 1.000000]\n",
            "209: [discriminator loss: 1.10414719581604, acc: 0.9921875] [gan loss: 0.000000, acc: 1.000000]\n",
            "210: [discriminator loss: 4.653440475463867, acc: 0.5] [gan loss: 0.000027, acc: 1.000000]\n",
            "211: [discriminator loss: 0.06367572396993637, acc: 1.0] [gan loss: 0.000083, acc: 1.000000]\n",
            "212: [discriminator loss: 0.03326428681612015, acc: 1.0] [gan loss: 0.000149, acc: 1.000000]\n",
            "213: [discriminator loss: 0.024988673627376556, acc: 1.0] [gan loss: 0.000237, acc: 1.000000]\n",
            "214: [discriminator loss: 0.02089717425405979, acc: 1.0] [gan loss: 0.000347, acc: 1.000000]\n",
            "215: [discriminator loss: 0.016767967492341995, acc: 1.0] [gan loss: 0.000477, acc: 1.000000]\n",
            "216: [discriminator loss: 0.014560094103217125, acc: 1.0] [gan loss: 0.000606, acc: 1.000000]\n",
            "217: [discriminator loss: 0.013092387467622757, acc: 1.0] [gan loss: 0.000743, acc: 1.000000]\n",
            "218: [discriminator loss: 0.01205116230994463, acc: 1.0] [gan loss: 0.000890, acc: 1.000000]\n",
            "219: [discriminator loss: 0.011158285662531853, acc: 1.0] [gan loss: 0.001016, acc: 1.000000]\n",
            "220: [discriminator loss: 0.012554783374071121, acc: 1.0] [gan loss: 0.001231, acc: 1.000000]\n",
            "221: [discriminator loss: 0.01016553957015276, acc: 1.0] [gan loss: 0.001320, acc: 1.000000]\n",
            "222: [discriminator loss: 0.011089165695011616, acc: 1.0] [gan loss: 0.001475, acc: 1.000000]\n",
            "223: [discriminator loss: 0.010092899203300476, acc: 1.0] [gan loss: 0.001540, acc: 1.000000]\n",
            "224: [discriminator loss: 0.010079268366098404, acc: 1.0] [gan loss: 0.001629, acc: 1.000000]\n",
            "225: [discriminator loss: 0.009835428558290005, acc: 1.0] [gan loss: 0.001684, acc: 1.000000]\n",
            "226: [discriminator loss: 0.009525206871330738, acc: 1.0] [gan loss: 0.001709, acc: 1.000000]\n",
            "227: [discriminator loss: 0.009305175393819809, acc: 1.0] [gan loss: 0.001721, acc: 1.000000]\n",
            "228: [discriminator loss: 0.010282453149557114, acc: 1.0] [gan loss: 0.001898, acc: 1.000000]\n",
            "229: [discriminator loss: 0.00906418077647686, acc: 1.0] [gan loss: 0.001800, acc: 1.000000]\n",
            "230: [discriminator loss: 0.009561534970998764, acc: 1.0] [gan loss: 0.001856, acc: 1.000000]\n",
            "231: [discriminator loss: 0.00942390039563179, acc: 1.0] [gan loss: 0.001930, acc: 1.000000]\n",
            "232: [discriminator loss: 0.009916695766150951, acc: 1.0] [gan loss: 0.002087, acc: 1.000000]\n",
            "233: [discriminator loss: 0.010710133239626884, acc: 1.0] [gan loss: 0.002349, acc: 1.000000]\n",
            "234: [discriminator loss: 0.010748423635959625, acc: 1.0] [gan loss: 0.002412, acc: 1.000000]\n",
            "235: [discriminator loss: 0.009672153741121292, acc: 1.0] [gan loss: 0.002128, acc: 1.000000]\n",
            "236: [discriminator loss: 0.01002112403512001, acc: 1.0] [gan loss: 0.002323, acc: 1.000000]\n",
            "237: [discriminator loss: 0.009571760892868042, acc: 1.0] [gan loss: 0.002159, acc: 1.000000]\n",
            "238: [discriminator loss: 0.010112191550433636, acc: 1.0] [gan loss: 0.002579, acc: 1.000000]\n",
            "239: [discriminator loss: 0.011194804683327675, acc: 1.0] [gan loss: 0.003015, acc: 1.000000]\n",
            "240: [discriminator loss: 0.01297959964722395, acc: 1.0] [gan loss: 0.003954, acc: 1.000000]\n",
            "241: [discriminator loss: 0.016218623146414757, acc: 1.0] [gan loss: 0.005915, acc: 1.000000]\n",
            "242: [discriminator loss: 0.03575621545314789, acc: 1.0] [gan loss: 0.274571, acc: 1.000000]\n",
            "243: [discriminator loss: 2.466212511062622, acc: 0.5] [gan loss: 10.111068, acc: 0.000000]\n",
            "244: [discriminator loss: 0.0018165258225053549, acc: 1.0] [gan loss: 0.027253, acc: 1.000000]\n",
            "245: [discriminator loss: 0.002648660447448492, acc: 1.0] [gan loss: 0.013236, acc: 1.000000]\n",
            "246: [discriminator loss: 0.0034419437870383263, acc: 1.0] [gan loss: 0.009672, acc: 1.000000]\n",
            "247: [discriminator loss: 0.0037434427067637444, acc: 1.0] [gan loss: 0.008121, acc: 1.000000]\n",
            "248: [discriminator loss: 0.004606610629707575, acc: 1.0] [gan loss: 0.007361, acc: 1.000000]\n",
            "249: [discriminator loss: 0.004998232703655958, acc: 1.0] [gan loss: 0.007047, acc: 1.000000]\n",
            "250: [discriminator loss: 0.00537141365930438, acc: 1.0] [gan loss: 0.006867, acc: 1.000000]\n",
            "251: [discriminator loss: 0.0052680978551507, acc: 1.0] [gan loss: 0.006772, acc: 1.000000]\n",
            "252: [discriminator loss: 0.005502793006598949, acc: 1.0] [gan loss: 0.006791, acc: 1.000000]\n",
            "253: [discriminator loss: 0.006104070693254471, acc: 1.0] [gan loss: 0.007297, acc: 1.000000]\n",
            "254: [discriminator loss: 0.005600756965577602, acc: 1.0] [gan loss: 0.007161, acc: 1.000000]\n",
            "255: [discriminator loss: 0.0062194569036364555, acc: 1.0] [gan loss: 0.007625, acc: 1.000000]\n",
            "256: [discriminator loss: 0.005880547221750021, acc: 1.0] [gan loss: 0.007807, acc: 1.000000]\n",
            "257: [discriminator loss: 0.0063612330704927444, acc: 1.0] [gan loss: 0.008210, acc: 1.000000]\n",
            "258: [discriminator loss: 0.0065055666491389275, acc: 1.0] [gan loss: 0.008817, acc: 1.000000]\n",
            "259: [discriminator loss: 0.006362629123032093, acc: 1.0] [gan loss: 0.008798, acc: 1.000000]\n",
            "260: [discriminator loss: 0.006359441205859184, acc: 1.0] [gan loss: 0.009085, acc: 1.000000]\n",
            "261: [discriminator loss: 0.006998080760240555, acc: 1.0] [gan loss: 0.010015, acc: 1.000000]\n",
            "262: [discriminator loss: 0.006806463468819857, acc: 1.0] [gan loss: 0.010389, acc: 1.000000]\n",
            "263: [discriminator loss: 0.007285088766366243, acc: 1.0] [gan loss: 0.011412, acc: 1.000000]\n",
            "264: [discriminator loss: 0.006139467004686594, acc: 1.0] [gan loss: 0.009475, acc: 1.000000]\n",
            "265: [discriminator loss: 0.0064067901112139225, acc: 1.0] [gan loss: 0.010269, acc: 1.000000]\n",
            "266: [discriminator loss: 0.007155260071158409, acc: 1.0] [gan loss: 0.012597, acc: 1.000000]\n",
            "267: [discriminator loss: 0.006879844702780247, acc: 1.0] [gan loss: 0.011056, acc: 1.000000]\n",
            "268: [discriminator loss: 0.00793454423546791, acc: 1.0] [gan loss: 0.017077, acc: 1.000000]\n",
            "269: [discriminator loss: 0.010514311492443085, acc: 1.0] [gan loss: 0.025480, acc: 1.000000]\n",
            "270: [discriminator loss: 0.025165250524878502, acc: 1.0] [gan loss: 0.935194, acc: 0.000000]\n",
            "271: [discriminator loss: 3.885974884033203, acc: 0.5] [gan loss: 14.084694, acc: 0.000000]\n",
            "272: [discriminator loss: 2.5575649488018826e-05, acc: 1.0] [gan loss: 5.460823, acc: 0.000000]\n",
            "273: [discriminator loss: 0.033484943211078644, acc: 1.0] [gan loss: 0.030121, acc: 1.000000]\n",
            "274: [discriminator loss: 0.011242963373661041, acc: 1.0] [gan loss: 0.033605, acc: 1.000000]\n",
            "275: [discriminator loss: 0.011306938715279102, acc: 1.0] [gan loss: 0.035458, acc: 1.000000]\n",
            "276: [discriminator loss: 0.010928923264145851, acc: 1.0] [gan loss: 0.035661, acc: 1.000000]\n",
            "277: [discriminator loss: 0.011393727734684944, acc: 1.0] [gan loss: 0.037721, acc: 1.000000]\n",
            "278: [discriminator loss: 0.011194255203008652, acc: 1.0] [gan loss: 0.037491, acc: 1.000000]\n",
            "279: [discriminator loss: 0.011708272621035576, acc: 1.0] [gan loss: 0.039612, acc: 1.000000]\n",
            "280: [discriminator loss: 0.012347678653895855, acc: 1.0] [gan loss: 0.042529, acc: 1.000000]\n",
            "281: [discriminator loss: 0.012682096101343632, acc: 1.0] [gan loss: 0.045867, acc: 1.000000]\n",
            "282: [discriminator loss: 0.013226005248725414, acc: 1.0] [gan loss: 0.047210, acc: 1.000000]\n",
            "283: [discriminator loss: 0.011797677725553513, acc: 1.0] [gan loss: 0.040307, acc: 1.000000]\n",
            "284: [discriminator loss: 0.01226736605167389, acc: 1.0] [gan loss: 0.045844, acc: 1.000000]\n",
            "285: [discriminator loss: 0.013390516862273216, acc: 1.0] [gan loss: 0.050771, acc: 1.000000]\n",
            "286: [discriminator loss: 0.01364605687558651, acc: 1.0] [gan loss: 0.050588, acc: 1.000000]\n",
            "287: [discriminator loss: 0.01542406901717186, acc: 1.0] [gan loss: 0.069001, acc: 1.000000]\n",
            "288: [discriminator loss: 0.023523129522800446, acc: 1.0] [gan loss: 0.181521, acc: 1.000000]\n",
            "289: [discriminator loss: 0.3021540343761444, acc: 0.8359375] [gan loss: 17.360130, acc: 0.000000]\n",
            "290: [discriminator loss: 1.0762742931547109e-05, acc: 1.0] [gan loss: 5.078573, acc: 0.000000]\n",
            "291: [discriminator loss: 0.7592892050743103, acc: 0.515625] [gan loss: 15.709792, acc: 0.000000]\n",
            "292: [discriminator loss: 2.4004975784919225e-06, acc: 1.0] [gan loss: 9.253558, acc: 0.000000]\n",
            "293: [discriminator loss: 0.00033882042043842375, acc: 1.0] [gan loss: 2.452244, acc: 0.000000]\n",
            "294: [discriminator loss: 0.1998825967311859, acc: 0.984375] [gan loss: 4.635138, acc: 0.000000]\n",
            "295: [discriminator loss: 0.02375783398747444, acc: 1.0] [gan loss: 0.119918, acc: 1.000000]\n",
            "296: [discriminator loss: 0.0178372822701931, acc: 1.0] [gan loss: 0.133149, acc: 1.000000]\n",
            "297: [discriminator loss: 0.019929159432649612, acc: 1.0] [gan loss: 0.153163, acc: 1.000000]\n",
            "298: [discriminator loss: 0.019987821578979492, acc: 1.0] [gan loss: 0.150196, acc: 1.000000]\n",
            "299: [discriminator loss: 0.02269762195646763, acc: 1.0] [gan loss: 0.203086, acc: 1.000000]\n",
            "300: [discriminator loss: 0.033369168639183044, acc: 1.0] [gan loss: 0.452816, acc: 1.000000]\n",
            "301: [discriminator loss: 0.14122390747070312, acc: 0.9921875] [gan loss: 7.937511, acc: 0.000000]\n",
            "302: [discriminator loss: 0.007505821064114571, acc: 1.0] [gan loss: 0.139652, acc: 1.000000]\n",
            "303: [discriminator loss: 0.015972819179296494, acc: 1.0] [gan loss: 0.149899, acc: 1.000000]\n",
            "304: [discriminator loss: 0.021125439554452896, acc: 1.0] [gan loss: 0.289689, acc: 1.000000]\n",
            "305: [discriminator loss: 0.0643409788608551, acc: 1.0] [gan loss: 4.028226, acc: 0.000000]\n",
            "306: [discriminator loss: 0.5426434278488159, acc: 0.5703125] [gan loss: 18.925201, acc: 0.000000]\n",
            "307: [discriminator loss: 7.402491064567585e-08, acc: 1.0] [gan loss: 13.205826, acc: 0.000000]\n",
            "308: [discriminator loss: 5.526389031729195e-06, acc: 1.0] [gan loss: 7.398335, acc: 0.000000]\n",
            "309: [discriminator loss: 0.0013478717301040888, acc: 1.0] [gan loss: 0.941911, acc: 0.000000]\n",
            "310: [discriminator loss: 0.09093168377876282, acc: 1.0] [gan loss: 2.442361, acc: 0.000000]\n",
            "311: [discriminator loss: 0.13397905230522156, acc: 1.0] [gan loss: 5.457250, acc: 0.000000]\n",
            "312: [discriminator loss: 0.0055733658373355865, acc: 1.0] [gan loss: 0.111635, acc: 1.000000]\n",
            "313: [discriminator loss: 0.011474324390292168, acc: 1.0] [gan loss: 0.124489, acc: 1.000000]\n",
            "314: [discriminator loss: 0.011322468519210815, acc: 1.0] [gan loss: 0.124684, acc: 1.000000]\n",
            "315: [discriminator loss: 0.013698326423764229, acc: 1.0] [gan loss: 0.174139, acc: 1.000000]\n",
            "316: [discriminator loss: 0.0154680535197258, acc: 1.0] [gan loss: 0.190786, acc: 1.000000]\n",
            "317: [discriminator loss: 0.019906699657440186, acc: 1.0] [gan loss: 0.339756, acc: 1.000000]\n",
            "318: [discriminator loss: 0.04947567731142044, acc: 1.0] [gan loss: 2.931325, acc: 0.000000]\n",
            "319: [discriminator loss: 0.509385883808136, acc: 0.6171875] [gan loss: 19.297396, acc: 0.000000]\n",
            "320: [discriminator loss: 6.338444709777832, acc: 0.9765625] [gan loss: 0.000061, acc: 1.000000]\n",
            "321: [discriminator loss: 0.9051699638366699, acc: 0.5234375] [gan loss: 0.625534, acc: 0.812500]\n",
            "322: [discriminator loss: 0.15320327877998352, acc: 0.984375] [gan loss: 0.142172, acc: 1.000000]\n",
            "323: [discriminator loss: 0.06275051087141037, acc: 1.0] [gan loss: 0.131809, acc: 1.000000]\n",
            "324: [discriminator loss: 0.06665454059839249, acc: 1.0] [gan loss: 0.128953, acc: 1.000000]\n",
            "325: [discriminator loss: 0.09983351826667786, acc: 1.0] [gan loss: 0.121085, acc: 1.000000]\n",
            "326: [discriminator loss: 0.15090835094451904, acc: 0.9921875] [gan loss: 0.199630, acc: 1.000000]\n",
            "327: [discriminator loss: 0.29159343242645264, acc: 0.8515625] [gan loss: 1.478307, acc: 0.000000]\n",
            "328: [discriminator loss: 3.7024478912353516, acc: 0.5] [gan loss: 0.445172, acc: 1.000000]\n",
            "329: [discriminator loss: 2.187947988510132, acc: 0.5] [gan loss: 0.338646, acc: 1.000000]\n",
            "330: [discriminator loss: 0.5727754831314087, acc: 0.5625] [gan loss: 0.872624, acc: 0.000000]\n",
            "331: [discriminator loss: 1.678470492362976, acc: 0.5] [gan loss: 0.714394, acc: 0.484375]\n",
            "332: [discriminator loss: 1.357569694519043, acc: 0.5] [gan loss: 1.003744, acc: 0.000000]\n",
            "333: [discriminator loss: 1.5988240242004395, acc: 0.5] [gan loss: 1.007145, acc: 0.000000]\n",
            "334: [discriminator loss: 1.3960057497024536, acc: 0.5] [gan loss: 0.875752, acc: 0.000000]\n",
            "335: [discriminator loss: 1.0419201850891113, acc: 0.5078125] [gan loss: 0.790983, acc: 0.000000]\n",
            "336: [discriminator loss: 0.6366541981697083, acc: 0.5078125] [gan loss: 0.673284, acc: 0.750000]\n",
            "337: [discriminator loss: 0.4368549883365631, acc: 0.6171875] [gan loss: 0.635919, acc: 0.890625]\n",
            "338: [discriminator loss: 0.3725131154060364, acc: 0.6640625] [gan loss: 0.583980, acc: 0.984375]\n",
            "339: [discriminator loss: 0.34019649028778076, acc: 0.765625] [gan loss: 0.569063, acc: 0.968750]\n",
            "340: [discriminator loss: 0.34777218103408813, acc: 0.7109375] [gan loss: 0.654602, acc: 0.765625]\n",
            "341: [discriminator loss: 0.3229507803916931, acc: 0.8046875] [gan loss: 0.592512, acc: 0.968750]\n",
            "342: [discriminator loss: 0.307450532913208, acc: 0.8359375] [gan loss: 0.625749, acc: 0.859375]\n",
            "343: [discriminator loss: 0.29380738735198975, acc: 0.859375] [gan loss: 0.606452, acc: 0.906250]\n",
            "344: [discriminator loss: 0.2971615791320801, acc: 0.8671875] [gan loss: 0.689391, acc: 0.609375]\n",
            "345: [discriminator loss: 0.2973431348800659, acc: 0.8203125] [gan loss: 0.698395, acc: 0.562500]\n",
            "346: [discriminator loss: 0.28070950508117676, acc: 0.8671875] [gan loss: 0.651596, acc: 0.781250]\n",
            "347: [discriminator loss: 0.2640608549118042, acc: 0.90625] [gan loss: 0.656904, acc: 0.796875]\n",
            "348: [discriminator loss: 0.23080185055732727, acc: 0.9453125] [gan loss: 0.508619, acc: 0.968750]\n",
            "349: [discriminator loss: 0.20447185635566711, acc: 0.96875] [gan loss: 0.456192, acc: 0.984375]\n",
            "350: [discriminator loss: 0.21299675107002258, acc: 0.9453125] [gan loss: 0.492967, acc: 0.937500]\n",
            "351: [discriminator loss: 0.26577016711235046, acc: 0.8671875] [gan loss: 0.909056, acc: 0.000000]\n",
            "352: [discriminator loss: 0.3363262414932251, acc: 0.78125] [gan loss: 1.240985, acc: 0.000000]\n",
            "353: [discriminator loss: 0.3461117446422577, acc: 0.7421875] [gan loss: 1.423137, acc: 0.000000]\n",
            "354: [discriminator loss: 0.2946198582649231, acc: 0.8515625] [gan loss: 1.311082, acc: 0.000000]\n",
            "355: [discriminator loss: 0.2895745635032654, acc: 0.8984375] [gan loss: 1.456500, acc: 0.000000]\n",
            "356: [discriminator loss: 0.25758999586105347, acc: 0.9375] [gan loss: 1.379505, acc: 0.000000]\n",
            "357: [discriminator loss: 0.2384616732597351, acc: 0.953125] [gan loss: 1.320883, acc: 0.000000]\n",
            "358: [discriminator loss: 0.2835460305213928, acc: 0.8828125] [gan loss: 1.462873, acc: 0.000000]\n",
            "359: [discriminator loss: 0.2418939173221588, acc: 0.96875] [gan loss: 1.381701, acc: 0.000000]\n",
            "360: [discriminator loss: 0.20671747624874115, acc: 0.9921875] [gan loss: 1.232563, acc: 0.000000]\n",
            "361: [discriminator loss: 0.1978917121887207, acc: 1.0] [gan loss: 1.306125, acc: 0.000000]\n",
            "362: [discriminator loss: 0.16334789991378784, acc: 1.0] [gan loss: 1.093738, acc: 0.000000]\n",
            "363: [discriminator loss: 0.16253972053527832, acc: 1.0] [gan loss: 1.154490, acc: 0.000000]\n",
            "364: [discriminator loss: 0.13807237148284912, acc: 1.0] [gan loss: 0.962114, acc: 0.000000]\n",
            "365: [discriminator loss: 0.1492849588394165, acc: 1.0] [gan loss: 1.177356, acc: 0.000000]\n",
            "366: [discriminator loss: 0.10807213187217712, acc: 1.0] [gan loss: 0.744059, acc: 0.187500]\n",
            "367: [discriminator loss: 0.12728039920330048, acc: 1.0] [gan loss: 1.026340, acc: 0.000000]\n",
            "368: [discriminator loss: 0.10745271295309067, acc: 1.0] [gan loss: 0.806074, acc: 0.000000]\n",
            "369: [discriminator loss: 0.12828633189201355, acc: 1.0] [gan loss: 1.188859, acc: 0.000000]\n",
            "370: [discriminator loss: 0.09513023495674133, acc: 1.0] [gan loss: 0.766938, acc: 0.093750]\n",
            "371: [discriminator loss: 0.10728470236063004, acc: 1.0] [gan loss: 0.946539, acc: 0.000000]\n",
            "372: [discriminator loss: 0.08533510565757751, acc: 1.0] [gan loss: 0.675615, acc: 0.687500]\n",
            "373: [discriminator loss: 0.09120495617389679, acc: 1.0] [gan loss: 0.835532, acc: 0.000000]\n",
            "374: [discriminator loss: 0.08467590808868408, acc: 1.0] [gan loss: 0.746053, acc: 0.187500]\n",
            "375: [discriminator loss: 0.08053597807884216, acc: 1.0] [gan loss: 0.763726, acc: 0.109375]\n",
            "376: [discriminator loss: 0.07204088568687439, acc: 1.0] [gan loss: 0.635183, acc: 0.906250]\n",
            "377: [discriminator loss: 0.0644737035036087, acc: 1.0] [gan loss: 0.578241, acc: 0.984375]\n",
            "378: [discriminator loss: 0.058842942118644714, acc: 1.0] [gan loss: 0.522696, acc: 0.953125]\n",
            "379: [discriminator loss: 0.05536751449108124, acc: 1.0] [gan loss: 0.490438, acc: 0.984375]\n",
            "380: [discriminator loss: 0.05311650037765503, acc: 1.0] [gan loss: 0.556679, acc: 0.984375]\n",
            "381: [discriminator loss: 0.05557383596897125, acc: 1.0] [gan loss: 0.584773, acc: 0.906250]\n",
            "382: [discriminator loss: 0.07535607367753983, acc: 1.0] [gan loss: 1.444479, acc: 0.000000]\n",
            "383: [discriminator loss: 0.08867248892784119, acc: 1.0] [gan loss: 1.271718, acc: 0.000000]\n",
            "384: [discriminator loss: 0.07994011044502258, acc: 1.0] [gan loss: 1.470344, acc: 0.000000]\n",
            "385: [discriminator loss: 0.07398547977209091, acc: 1.0] [gan loss: 1.236992, acc: 0.000000]\n",
            "386: [discriminator loss: 0.0673292875289917, acc: 1.0] [gan loss: 1.271613, acc: 0.000000]\n",
            "387: [discriminator loss: 0.06698843836784363, acc: 1.0] [gan loss: 1.355953, acc: 0.000000]\n",
            "388: [discriminator loss: 0.06714871525764465, acc: 1.0] [gan loss: 1.512207, acc: 0.000000]\n",
            "389: [discriminator loss: 0.060110487043857574, acc: 1.0] [gan loss: 1.355536, acc: 0.000000]\n",
            "390: [discriminator loss: 0.06452229619026184, acc: 1.0] [gan loss: 1.633065, acc: 0.000000]\n",
            "391: [discriminator loss: 0.05988287925720215, acc: 1.0] [gan loss: 1.489648, acc: 0.000000]\n",
            "392: [discriminator loss: 0.17254723608493805, acc: 1.0] [gan loss: 4.359324, acc: 0.000000]\n",
            "393: [discriminator loss: 0.3392394781112671, acc: 0.71875] [gan loss: 5.649952, acc: 0.000000]\n",
            "394: [discriminator loss: 0.017379937693476677, acc: 1.0] [gan loss: 3.051803, acc: 0.000000]\n",
            "395: [discriminator loss: 0.1056264117360115, acc: 1.0] [gan loss: 2.911922, acc: 0.000000]\n",
            "396: [discriminator loss: 0.08731161057949066, acc: 1.0] [gan loss: 2.802478, acc: 0.000000]\n",
            "397: [discriminator loss: 0.08037504553794861, acc: 1.0] [gan loss: 2.757892, acc: 0.000000]\n",
            "398: [discriminator loss: 0.07604174315929413, acc: 1.0] [gan loss: 2.761250, acc: 0.000000]\n",
            "399: [discriminator loss: 0.06776341795921326, acc: 1.0] [gan loss: 2.675752, acc: 0.000000]\n",
            "400: [discriminator loss: 0.06724250316619873, acc: 1.0] [gan loss: 2.660954, acc: 0.000000]\n",
            "401: [discriminator loss: 0.06941938400268555, acc: 1.0] [gan loss: 2.799994, acc: 0.000000]\n",
            "402: [discriminator loss: 0.06095895171165466, acc: 1.0] [gan loss: 2.761700, acc: 0.000000]\n",
            "403: [discriminator loss: 0.059164538979530334, acc: 1.0] [gan loss: 2.765118, acc: 0.000000]\n",
            "404: [discriminator loss: 0.05650850757956505, acc: 1.0] [gan loss: 2.772903, acc: 0.000000]\n",
            "405: [discriminator loss: 0.05226371809840202, acc: 1.0] [gan loss: 2.690531, acc: 0.000000]\n",
            "406: [discriminator loss: 0.06557780504226685, acc: 1.0] [gan loss: 3.174956, acc: 0.000000]\n",
            "407: [discriminator loss: 0.043138064444065094, acc: 1.0] [gan loss: 2.886073, acc: 0.000000]\n",
            "408: [discriminator loss: 0.061743900179862976, acc: 1.0] [gan loss: 3.512004, acc: 0.000000]\n",
            "409: [discriminator loss: 0.03345032036304474, acc: 1.0] [gan loss: 3.007347, acc: 0.000000]\n",
            "410: [discriminator loss: 0.05394537001848221, acc: 1.0] [gan loss: 3.589618, acc: 0.000000]\n",
            "411: [discriminator loss: 0.03054032474756241, acc: 1.0] [gan loss: 3.132614, acc: 0.000000]\n",
            "412: [discriminator loss: 0.04472631216049194, acc: 1.0] [gan loss: 3.497276, acc: 0.000000]\n",
            "413: [discriminator loss: 0.033742018043994904, acc: 1.0] [gan loss: 3.348493, acc: 0.000000]\n",
            "414: [discriminator loss: 0.03380284458398819, acc: 1.0] [gan loss: 3.336052, acc: 0.000000]\n",
            "415: [discriminator loss: 0.039543427526950836, acc: 1.0] [gan loss: 3.709582, acc: 0.000000]\n",
            "416: [discriminator loss: 0.02411809004843235, acc: 1.0] [gan loss: 3.235511, acc: 0.000000]\n",
            "417: [discriminator loss: 0.038689084351062775, acc: 1.0] [gan loss: 3.752636, acc: 0.000000]\n",
            "418: [discriminator loss: 0.023762967437505722, acc: 1.0] [gan loss: 3.342231, acc: 0.000000]\n",
            "419: [discriminator loss: 0.03328108787536621, acc: 1.0] [gan loss: 3.672216, acc: 0.000000]\n",
            "420: [discriminator loss: 0.02543327584862709, acc: 1.0] [gan loss: 3.478599, acc: 0.000000]\n",
            "421: [discriminator loss: 0.028034405782818794, acc: 1.0] [gan loss: 3.561988, acc: 0.000000]\n",
            "422: [discriminator loss: 0.029005803167819977, acc: 1.0] [gan loss: 3.725360, acc: 0.000000]\n",
            "423: [discriminator loss: 0.026236116886138916, acc: 1.0] [gan loss: 3.555682, acc: 0.000000]\n",
            "424: [discriminator loss: 0.02804795652627945, acc: 1.0] [gan loss: 3.581989, acc: 0.000000]\n",
            "425: [discriminator loss: 0.02428559958934784, acc: 1.0] [gan loss: 3.356187, acc: 0.000000]\n",
            "426: [discriminator loss: 0.04303128272294998, acc: 1.0] [gan loss: 5.170842, acc: 0.000000]\n",
            "427: [discriminator loss: 0.005606699734926224, acc: 1.0] [gan loss: 3.407552, acc: 0.000000]\n",
            "428: [discriminator loss: 0.034560129046440125, acc: 1.0] [gan loss: 4.596821, acc: 0.000000]\n",
            "429: [discriminator loss: 0.010183057747781277, acc: 1.0] [gan loss: 3.531558, acc: 0.000000]\n",
            "430: [discriminator loss: 0.03064364194869995, acc: 1.0] [gan loss: 4.615390, acc: 0.000000]\n",
            "431: [discriminator loss: 0.00986967608332634, acc: 1.0] [gan loss: 3.621862, acc: 0.000000]\n",
            "432: [discriminator loss: 0.030363406985998154, acc: 1.0] [gan loss: 4.953988, acc: 0.000000]\n",
            "433: [discriminator loss: 0.006547047756612301, acc: 1.0] [gan loss: 3.699782, acc: 0.000000]\n",
            "434: [discriminator loss: 0.029641933739185333, acc: 1.0] [gan loss: 5.116526, acc: 0.000000]\n",
            "435: [discriminator loss: 0.006269339472055435, acc: 1.0] [gan loss: 3.898769, acc: 0.000000]\n",
            "436: [discriminator loss: 0.021285317838191986, acc: 1.0] [gan loss: 4.535326, acc: 0.000000]\n",
            "437: [discriminator loss: 0.011336764320731163, acc: 1.0] [gan loss: 3.978138, acc: 0.000000]\n",
            "438: [discriminator loss: 0.025263454765081406, acc: 1.0] [gan loss: 5.231687, acc: 0.000000]\n",
            "439: [discriminator loss: 0.007393865846097469, acc: 1.0] [gan loss: 3.804838, acc: 0.000000]\n",
            "440: [discriminator loss: 0.09467516839504242, acc: 1.0] [gan loss: 9.275845, acc: 0.000000]\n",
            "441: [discriminator loss: 0.0002460674149915576, acc: 1.0] [gan loss: 6.641885, acc: 0.000000]\n",
            "442: [discriminator loss: 0.02321052923798561, acc: 1.0] [gan loss: 5.707343, acc: 0.000000]\n",
            "443: [discriminator loss: 0.34191516041755676, acc: 0.796875] [gan loss: 10.660501, acc: 0.000000]\n",
            "444: [discriminator loss: 0.00015678862109780312, acc: 1.0] [gan loss: 7.809681, acc: 0.000000]\n",
            "445: [discriminator loss: 0.0012825299054384232, acc: 1.0] [gan loss: 5.657151, acc: 0.000000]\n",
            "446: [discriminator loss: 0.009791094809770584, acc: 1.0] [gan loss: 3.958862, acc: 0.000000]\n",
            "447: [discriminator loss: 0.05774683505296707, acc: 1.0] [gan loss: 4.191340, acc: 0.000000]\n",
            "448: [discriminator loss: 0.046745046973228455, acc: 1.0] [gan loss: 4.100698, acc: 0.000000]\n",
            "449: [discriminator loss: 0.05740733444690704, acc: 1.0] [gan loss: 4.626227, acc: 0.000000]\n",
            "450: [discriminator loss: 0.036641474813222885, acc: 1.0] [gan loss: 4.190446, acc: 0.000000]\n",
            "451: [discriminator loss: 0.05342591181397438, acc: 1.0] [gan loss: 4.816854, acc: 0.000000]\n",
            "452: [discriminator loss: 0.030239567160606384, acc: 1.0] [gan loss: 4.255879, acc: 0.000000]\n",
            "453: [discriminator loss: 0.047928761690855026, acc: 1.0] [gan loss: 5.052478, acc: 0.000000]\n",
            "454: [discriminator loss: 0.025434687733650208, acc: 1.0] [gan loss: 4.377899, acc: 0.000000]\n",
            "455: [discriminator loss: 0.04530793055891991, acc: 1.0] [gan loss: 5.317042, acc: 0.000000]\n",
            "456: [discriminator loss: 0.019459184259176254, acc: 1.0] [gan loss: 4.307269, acc: 0.000000]\n",
            "457: [discriminator loss: 0.05153954029083252, acc: 1.0] [gan loss: 6.229236, acc: 0.000000]\n",
            "458: [discriminator loss: 0.007973583415150642, acc: 1.0] [gan loss: 4.274489, acc: 0.000000]\n",
            "459: [discriminator loss: 0.04580603167414665, acc: 1.0] [gan loss: 6.057960, acc: 0.000000]\n",
            "460: [discriminator loss: 0.008715139701962471, acc: 1.0] [gan loss: 4.316939, acc: 0.000000]\n",
            "461: [discriminator loss: 0.04019186273217201, acc: 1.0] [gan loss: 5.992643, acc: 0.000000]\n",
            "462: [discriminator loss: 0.010058039799332619, acc: 1.0] [gan loss: 4.414234, acc: 0.000000]\n",
            "463: [discriminator loss: 0.0439971499145031, acc: 1.0] [gan loss: 6.821980, acc: 0.000000]\n",
            "464: [discriminator loss: 0.00419353973120451, acc: 1.0] [gan loss: 4.579408, acc: 0.000000]\n",
            "465: [discriminator loss: 0.029566772282123566, acc: 1.0] [gan loss: 5.665520, acc: 0.000000]\n",
            "466: [discriminator loss: 0.011633453890681267, acc: 1.0] [gan loss: 4.573373, acc: 0.000000]\n",
            "467: [discriminator loss: 0.03257998824119568, acc: 1.0] [gan loss: 6.460627, acc: 0.000000]\n",
            "468: [discriminator loss: 0.005444743670523167, acc: 1.0] [gan loss: 4.510528, acc: 0.000000]\n",
            "469: [discriminator loss: 0.03346918523311615, acc: 1.0] [gan loss: 6.866584, acc: 0.000000]\n",
            "470: [discriminator loss: 0.004097996279597282, acc: 1.0] [gan loss: 4.742512, acc: 0.000000]\n",
            "471: [discriminator loss: 0.024994006380438805, acc: 1.0] [gan loss: 6.111923, acc: 0.000000]\n",
            "472: [discriminator loss: 0.007895177230238914, acc: 1.0] [gan loss: 4.721148, acc: 0.000000]\n",
            "473: [discriminator loss: 0.025443654507398605, acc: 1.0] [gan loss: 6.588076, acc: 0.000000]\n",
            "474: [discriminator loss: 0.005619306117296219, acc: 1.0] [gan loss: 4.832899, acc: 0.000000]\n",
            "475: [discriminator loss: 0.024961408227682114, acc: 1.0] [gan loss: 6.984990, acc: 0.000000]\n",
            "476: [discriminator loss: 0.0035784835927188396, acc: 1.0] [gan loss: 4.860525, acc: 0.000000]\n",
            "477: [discriminator loss: 0.024653196334838867, acc: 1.0] [gan loss: 7.274313, acc: 0.000000]\n",
            "478: [discriminator loss: 0.002585515845566988, acc: 1.0] [gan loss: 4.979290, acc: 0.000000]\n",
            "479: [discriminator loss: 0.02195725589990616, acc: 1.0] [gan loss: 7.138556, acc: 0.000000]\n",
            "480: [discriminator loss: 0.002748851664364338, acc: 1.0] [gan loss: 4.982549, acc: 0.000000]\n",
            "481: [discriminator loss: 0.02258538454771042, acc: 1.0] [gan loss: 7.623054, acc: 0.000000]\n",
            "482: [discriminator loss: 0.0017667929641902447, acc: 1.0] [gan loss: 5.261895, acc: 0.000000]\n",
            "483: [discriminator loss: 0.01632167212665081, acc: 1.0] [gan loss: 6.641784, acc: 0.000000]\n",
            "484: [discriminator loss: 0.004247513599693775, acc: 1.0] [gan loss: 5.061994, acc: 0.000000]\n",
            "485: [discriminator loss: 0.02103661559522152, acc: 1.0] [gan loss: 7.970322, acc: 0.000000]\n",
            "486: [discriminator loss: 0.0012268108548596501, acc: 1.0] [gan loss: 5.522307, acc: 0.000000]\n",
            "487: [discriminator loss: 0.012428732588887215, acc: 1.0] [gan loss: 6.353797, acc: 0.000000]\n",
            "488: [discriminator loss: 0.005444088019430637, acc: 1.0] [gan loss: 5.309910, acc: 0.000000]\n",
            "489: [discriminator loss: 0.01608167216181755, acc: 1.0] [gan loss: 7.571274, acc: 0.000000]\n",
            "490: [discriminator loss: 0.0018686901312321424, acc: 1.0] [gan loss: 5.415226, acc: 0.000000]\n",
            "491: [discriminator loss: 0.014790831133723259, acc: 1.0] [gan loss: 7.570999, acc: 0.000000]\n",
            "492: [discriminator loss: 0.00178558100014925, acc: 1.0] [gan loss: 5.463835, acc: 0.000000]\n",
            "493: [discriminator loss: 0.014882586896419525, acc: 1.0] [gan loss: 7.966361, acc: 0.000000]\n",
            "494: [discriminator loss: 0.001168381073512137, acc: 1.0] [gan loss: 5.656242, acc: 0.000000]\n",
            "495: [discriminator loss: 0.012371144257485867, acc: 1.0] [gan loss: 7.561790, acc: 0.000000]\n",
            "496: [discriminator loss: 0.0016658359672874212, acc: 1.0] [gan loss: 5.524935, acc: 0.000000]\n",
            "497: [discriminator loss: 0.01483596209436655, acc: 1.0] [gan loss: 8.675093, acc: 0.000000]\n",
            "498: [discriminator loss: 0.000599471153691411, acc: 1.0] [gan loss: 6.112494, acc: 0.000000]\n",
            "499: [discriminator loss: 0.007899146527051926, acc: 1.0] [gan loss: 6.782819, acc: 0.000000]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-9776ad56bd27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-be667860f699>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(models, x_train)\u001b[0m\n\u001b[1;32m     32\u001b[0m                         \u001b[0mshow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                         \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                         model_name=model_name)\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_name' is not defined"
          ]
        }
      ]
    }
  ]
}